{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (IV) Creando el Modelo\n",
    "También puedes entrenar la red neuronal con tus propios datos y construir y probar tu propio modelo usando los siguientes módulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes construir tu propio EQTransformer con diferentes tamaños de codificador (encoder) y entrenarlo usando tus propios datos. Tus datos deben estar en el mismo formato que nuestros datos de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 6000, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 6000, 8)      272         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3000, 8)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 3000, 16)     1168        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1500, 16)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1500, 16)     1808        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 750, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 750, 32)      3616        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 375, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 375, 32)      5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 188, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 188, 64)      10304       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 94, 64)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 94, 64)       12352       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 47, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 47, 64)       256         max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 47, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 47, 64)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 47, 64)       256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 47, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 47, 64)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 47, 64)       256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 47, 64)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 47, 64)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 47, 64)       12352       spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 47, 64)       256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 47, 64)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 47, 64)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 47, 64)       12352       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 47, 64)       0           add[0][0]                        \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 47, 32)       10368       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 47, 16)       528         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 47, 16)       64          conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentionD0 (SeqSelfAttention)  [(None, None, 16), ( 1089        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 47, 16)       0           batch_normalization_4[0][0]      \n",
      "                                                                 attentionD0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 47, 16)       32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward (FeedForward)      (None, 47, 16)       4240        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 47, 16)       0           layer_normalization[0][0]        \n",
      "                                                                 feed_forward[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 47, 16)       32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attentionD (SeqSelfAttention)   [(None, None, 16), ( 1089        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 47, 16)       0           layer_normalization_1[0][0]      \n",
      "                                                                 attentionD[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 47, 16)       32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward_1 (FeedForward)    (None, 47, 16)       4240        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 47, 16)       0           layer_normalization_2[0][0]      \n",
      "                                                                 feed_forward_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 47, 16)       32          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 47, 16)       2112        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attentionP (SeqSelfAttention)   [(None, None, 16), ( 1089        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attentionS (SeqSelfAttention)   [(None, None, 16), ( 1089        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 94, 16)       0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1D)  (None, None, 16)     0           attentionP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling1D) (None, None, 16)     0           attentionS[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 94, 64)       3136        up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 64)     3136        up_sampling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 64)     3136        up_sampling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 188, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, None, 64)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling1D) (None, None, 64)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 188, 64)      20544       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 64)     20544       up_sampling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, None, 64)     20544       up_sampling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 376, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1D)  (None, None, 64)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling1D) (None, None, 64)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 376, 32)      10272       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 32)     10272       up_sampling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, None, 32)     10272       up_sampling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 752, 32)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling1D) (None, None, 32)     0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling1D) (None, None, 32)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d (Cropping1D)         (None, 750, 32)      0           up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)       (None, None, 32)     0           up_sampling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)       (None, None, 32)     0           up_sampling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 750, 32)      7200        cropping1d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 32)     7200        cropping1d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, None, 32)     7200        cropping1d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1D)  (None, 1500, 32)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_11 (UpSampling1D) (None, None, 32)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_18 (UpSampling1D) (None, None, 32)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1500, 16)     3600        up_sampling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 16)     3600        up_sampling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, None, 16)     3600        up_sampling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, 3000, 16)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_12 (UpSampling1D) (None, None, 16)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_19 (UpSampling1D) (None, None, 16)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 3000, 16)     2320        up_sampling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 16)     2320        up_sampling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, None, 16)     2320        up_sampling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1D)  (None, 6000, 16)     0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_13 (UpSampling1D) (None, None, 16)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling1D) (None, None, 16)     0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 6000, 8)      1416        up_sampling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 8)      1416        up_sampling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, None, 8)      1416        up_sampling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detector (Conv1D)               (None, 6000, 1)      89          conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_P (Conv1D)               (None, None, 1)      89          conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "picker_S (Conv1D)               (None, None, 1)      89          conv1d_32[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 258,983\n",
      "Trainable params: 258,439\n",
      "Non-trainable params: 544\n",
      "__________________________________________________________________________________________________\n",
      "Started training in generator mode ...\n",
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.5697 - detector_loss: 0.6106 - picker_P_loss: 0.5268 - picker_S_loss: 0.5954 - detector_f1: 0.0416 - picker_P_f1: 0.0000e+00 - picker_S_f1: 7.6700e-05WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5200 - detector_loss: 0.5888 - picker_P_loss: 0.4643 - picker_S_loss: 0.5525 - detector_f1: 0.0347 - picker_P_f1: 0.0000e+00 - picker_S_f1: 6.3917e-05WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20194, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_001.h5\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.5200 - detector_loss: 0.5888 - picker_P_loss: 0.4643 - picker_S_loss: 0.5525 - detector_f1: 0.0347 - picker_P_f1: 0.0000e+00 - picker_S_f1: 6.3917e-05 - val_loss: 0.2019 - val_detector_loss: 0.4937 - val_picker_P_loss: 0.0816 - val_picker_S_loss: 0.2609 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0882 - detector_loss: 0.5244 - picker_P_loss: 0.0504 - picker_S_loss: 0.0740 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0895 - detector_loss: 0.5198 - picker_P_loss: 0.0560 - picker_S_loss: 0.0726 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20194 to 0.07672, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_002.h5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0895 - detector_loss: 0.5198 - picker_P_loss: 0.0560 - picker_S_loss: 0.0726 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0767 - val_detector_loss: 0.5975 - val_picker_P_loss: 0.0603 - val_picker_S_loss: 0.0390 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.1133 - detector_loss: 0.4840 - picker_P_loss: 0.0947 - picker_S_loss: 0.0909 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1103 - detector_loss: 0.4688 - picker_P_loss: 0.0913 - picker_S_loss: 0.0892 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07672\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.1103 - detector_loss: 0.4688 - picker_P_loss: 0.0913 - picker_S_loss: 0.0892 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0785 - val_detector_loss: 0.6278 - val_picker_P_loss: 0.0586 - val_picker_S_loss: 0.0406 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 1s - loss: 0.0834 - detector_loss: 0.4649 - picker_P_loss: 0.0590 - picker_S_loss: 0.0641 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0794 - detector_loss: 0.4612 - picker_P_loss: 0.0559 - picker_S_loss: 0.0594 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07672 to 0.06391, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_004.h5\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.0794 - detector_loss: 0.4612 - picker_P_loss: 0.0559 - picker_S_loss: 0.0594 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0639 - val_detector_loss: 0.6524 - val_picker_P_loss: 0.0363 - val_picker_S_loss: 0.0282 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0553 - detector_loss: 0.4223 - picker_P_loss: 0.0376 - picker_S_loss: 0.0324 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0560 - detector_loss: 0.4272 - picker_P_loss: 0.0385 - picker_S_loss: 0.0327 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06391\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.0560 - detector_loss: 0.4272 - picker_P_loss: 0.0385 - picker_S_loss: 0.0327 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0704 - val_detector_loss: 0.6135 - val_picker_P_loss: 0.0282 - val_picker_S_loss: 0.0494 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0552 - detector_loss: 0.4011 - picker_P_loss: 0.0391 - picker_S_loss: 0.0331 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0540 - detector_loss: 0.3936 - picker_P_loss: 0.0380 - picker_S_loss: 0.0324 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06391 to 0.05759, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_006.h5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.0540 - detector_loss: 0.3936 - picker_P_loss: 0.0380 - picker_S_loss: 0.0324 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0576 - val_detector_loss: 0.5683 - val_picker_P_loss: 0.0308 - val_picker_S_loss: 0.0283 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0528 - detector_loss: 0.4069 - picker_P_loss: 0.0361 - picker_S_loss: 0.0305 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0530 - detector_loss: 0.4099 - picker_P_loss: 0.0360 - picker_S_loss: 0.0306 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05759 to 0.05523, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_007.h5\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.0530 - detector_loss: 0.4099 - picker_P_loss: 0.0360 - picker_S_loss: 0.0306 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0552 - val_detector_loss: 0.5482 - val_picker_P_loss: 0.0293 - val_picker_S_loss: 0.0269 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 1s - loss: 0.0478 - detector_loss: 0.3616 - picker_P_loss: 0.0322 - picker_S_loss: 0.0283 - detector_f1: 0.0000e+00 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0483 - detector_loss: 0.3707 - picker_P_loss: 0.0321 - picker_S_loss: 0.0284 - detector_f1: 5.3041e-05 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05523 to 0.05252, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_008.h5\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.0483 - detector_loss: 0.3707 - picker_P_loss: 0.0321 - picker_S_loss: 0.0284 - detector_f1: 5.3041e-05 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0525 - val_detector_loss: 0.5157 - val_picker_P_loss: 0.0260 - val_picker_S_loss: 0.0274 - val_detector_f1: 0.0000e+00 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0437 - detector_loss: 0.3364 - picker_P_loss: 0.0294 - picker_S_loss: 0.0252 - detector_f1: 0.4367 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0445 - detector_loss: 0.3469 - picker_P_loss: 0.0297 - picker_S_loss: 0.0256 - detector_f1: 0.4762 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05252\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0445 - detector_loss: 0.3469 - picker_P_loss: 0.0297 - picker_S_loss: 0.0256 - detector_f1: 0.4762 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0539 - val_detector_loss: 0.5231 - val_picker_P_loss: 0.0263 - val_picker_S_loss: 0.0290 - val_detector_f1: 0.5047 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "5/6 [========================>.....] - ETA: 2s - loss: 0.0457 - detector_loss: 0.3577 - picker_P_loss: 0.0297 - picker_S_loss: 0.0266 - detector_f1: 0.6872 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0457 - detector_loss: 0.3552 - picker_P_loss: 0.0297 - picker_S_loss: 0.0270 - detector_f1: 0.6815 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05252 to 0.04782, saving model to /home/santiago/Coding University/PFC-TRANSFORMER-EQ/examples/test_trainer_outputs/models/test_trainer_010.h5\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0457 - detector_loss: 0.3552 - picker_P_loss: 0.0297 - picker_S_loss: 0.0270 - detector_f1: 0.6815 - picker_P_f1: 0.0000e+00 - picker_S_f1: 0.0000e+00 - val_loss: 0.0478 - val_detector_loss: 0.4675 - val_picker_P_loss: 0.0247 - val_picker_S_loss: 0.0242 - val_detector_f1: 0.5908 - val_picker_P_f1: 0.0000e+00 - val_picker_S_f1: 0.0000e+00 - lr: 0.0010\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-076f3418cdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgpuid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         gpu_limit=None)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/eqt36/lib/python3.6/site-packages/EQTransformer/core/trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(input_hdf5, input_csv, output_name, input_dimention, cnn_blocks, lstm_blocks, padding, activation, drop_rate, shuffle, label_type, normalization_mode, augmentation, add_event_r, shift_event_r, add_noise_r, drop_channel_r, add_gap_r, scale_amplitude_r, pre_emphasis, loss_weights, loss_types, train_valid_test_split, mode, batch_size, epochs, monitor, patience, multi_gpu, number_of_gpus, gpuid, gpu_limit, use_multiprocessing)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0m_document_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eqt36/lib/python3.6/site-packages/EQTransformer/core/trainer.py\u001b[0m in \u001b[0;36m_document_training\u001b[0;34m(history, model, start_training, end_training, save_dir, save_models, training_size, validation_size, args)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \"\"\"   \n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/history'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/final_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eqt36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 529\u001b[0;31m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eqt36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.trainer import trainer\n",
    "trainer(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "        input_csv='../ModelsAndSampleData/100samples.csv',\n",
    "        output_name='test_trainer',                \n",
    "        cnn_blocks=2,\n",
    "        lstm_blocks=1,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        drop_rate=0.2,\n",
    "        label_type='gaussian',\n",
    "        add_event_r=0.6,\n",
    "        add_gap_r=0.2,\n",
    "        shift_event_r=0.9,\n",
    "        add_noise_r=0.5, \n",
    "        mode='generator',\n",
    "        train_valid_test_split=[0.60, 0.20, 0.20],\n",
    "        batch_size=20,\n",
    "        epochs=10, \n",
    "        patience=2,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Testeando el Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego puedes probar el modelo que acabas de entrenar basándote en las etiquetas de verdad terreno (ground truth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "Loading is complete!\n",
      "Testing ...\n",
      "Writting results into: \" test_tester_outputs \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:14<00:00,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.tester import tester\n",
    "tester(input_hdf5='../ModelsAndSampleData/100samples.hdf5',\n",
    "       input_testset='test_trainer_outputs/test.npy',\n",
    "       input_model='test_trainer_outputs/models/test_trainer_010.h5',\n",
    "       output_name='test_tester',\n",
    "       detection_threshold=0.20,                \n",
    "       P_threshold=0.1,\n",
    "       S_threshold=0.1, \n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True, \n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=10,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqt36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
